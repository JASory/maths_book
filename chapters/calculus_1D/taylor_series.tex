\section{Taylor series}
Unlike most real functions, polynomials are relatively easy to calculate for any real value $x$. For example, to correctly calculate the value of the polynomial $P(x)=x^{2}-2x+5$ we simply need to know how to perform the following operations: addition, subtraction, muliplication and raising by an integer power, all operations that are easy for both humans and computers to perform.

Ideally, we would like to use polynomials for all calculations, e.g. given the function $f(x) = \cos(x)$ it would be great if we could find some polynomial $P(x)$ of a finite order $n$ for which $P(x)=\cos(x)$. Unfortunately such a polynomials does not exist, nor does such polynomials exist for $\sin(x), \sqrt{x}, \EU{x}, a^{x}\ \left(a>0\right)$ or any of the so-called fundamental functions and their compositions (except, of course, polynomials). The reason for this fact is rather complicated, but in short it lies in the fact that these functions are \textit{non-algebric}\footnote{technically $\sqrt{x}$ is algebraic, and there are indeed many methods to calculate its values - but non of these methods are as simple as calculating a polynomial\dots except the one we discuss in this section.}.

However, we do know at least one value of each of these functions with infinite precision in at least one $x\in\Rs$, sometimes at several values of $x$ or even at infinitely many values of $x$. For example, we know that $\cos(0)=1$ and $\cos\left(\frac{1}{2}\pi\right)=0$. From symmetry we thus know that $\cos(\pi)=-1$ and $\cos\left(\frac{3}{4}\pi\right)=0$. Since $\cos(x)$ is periodic, i.e. $\cos\left(x+2\pi k\right)=\cos(x)$ for any $k\in\mathbb{Z}$, we actually know infinitely many values of the function. For $\EU{x}$ we know that $\EU{0}=1$ and $\EU{1}=\eu$. One can argue that since $\eu$ is not algebraic, we don't \textit{really} know its value (i.e. we can't calculate it an infinite precision), but even it that case we still definitely know the value of $\EU{0}$ with inifnite precision.

We can use this knowledge to constract a polynomial which approximates the function's value in any $x\in\Rs$ to whatever precision we wish, given that a specific condition is met. We will describe this condition later, but first let's use an example function to construct such a polynomial: $\EU{x}$. Since we only know $\EU{0}$ with infinite precision, we can use it as a simple approximation of $\Eu{x}$, i.e
\begin{equation}
  \EU{x} = 1.
  \label{eq:zero_order_approx_exp}
\end{equation}
(see \autoref{fig:zero_order_approx_exp})

\begin{figure}
  \centering
  \begin{tikzpicture}
    \begin{axis}[
      graph2d,
      width=12cm, height=12cm,
      xmin=-4, xmax=5,
      ymin=-1, ymax=17,
      major grid style={black!10},
      minor grid style={black!5},
    ]
      \addplot[function, xred] {exp(x)};
      \addplot[function, xblue] {1};
      \foreach \xi in {-3.5, -3, ..., -0.5, 0.5, 1, ..., 3} {
        \edef\temp{\noexpand\draw[thick, dashed] (\xi, 1) -- (\xi, {exp(\xi)});}
          \temp
        }
    \end{axis}
  \end{tikzpicture}
  \caption{The 0th-order approximation $\Eu{x}=1$. The dashed lines show the diffence between the approximation and the actual function as $x$ diverges from $0$.}
  \label{fig:zero_order_approx_exp}
\end{figure}

Will call this the \emph{0th-order approximation} of $\EU{x}$ and denote it by $T_{0}(x)$. Obviously, this is not a particularly good approximation: it gets better as we approach $x=0$, but rapidly diverges from the actual value of $\EU{x}$ as we change $x$. More precisely, the absolute difference between $\EU{x}$ and our approximation is
\begin{equation}
  \Err_{0}(x) = \lvert \EU{x} - T_{0}(x) \rvert = \lvert \EU{x}-1 \rvert,
  \label{eq:exp_err_0}
\end{equation}
i.e. the error essentialy grows as $\EU{x}$ which is\dots not great.

Ok, then perhaps we can add another term to the approximation? After all, our notation pretty much suggests that\footnote{more like \textit{screams} it.}. We know that close to a point $a$ a function behaves pretty much like its derivative at that point. We also know the value of the derivative of $\EU{x}$ at $x=0$, i.e. $\exp'(0)=1$, so we can add a line of slop $m=1$ to our approximation, yielding:
\begin{equation}
  \EU{x} = 1 + x\cdot\exp'\left(0\right) = 1+x.
  \label{eq:first_order_approx_exp}
\end{equation}

Of course, we call this the \emph{1st-order approximation} of $\EU{x}$. Looking at \autoref{fig:first_order_approx_exp} we see that this approximation is better than the previous one, at least for positive values of $x$ and values close to $x=0$. The error behaves a bit better, i.e
\begin{equation}
  \Err_{1}(x) = \lvert \EU{x} - T_{1}(x) \rvert = \lvert \EU{x}-x-1 \rvert,
  \label{eq:exp_err_1}
\end{equation}
which still generally grows as $\EU{x}$, but closer to $x=0$ it grows more like $\EU{x}-x$, so still not great - but definitely an improvement over $\Err_{0}(x)$.

\begin{figure}
  \centering
  \begin{tikzpicture}
    \begin{axis}[
      graph2d,
      width=12cm, height=12cm,
      xmin=-5, xmax=5,
      ymin=-4, ymax=19,
      major grid style={black!10},
      minor grid style={black!5},
    ]
      \addplot[function, xred] {exp(x)};
      \addplot[function, xblue] {1+x};
      \foreach \xi in {-4.5, -4, ..., -2, 1, 1.5, ..., 3} {
        \edef\temp{\noexpand\draw[thick, dashed] (\xi, {\xi+1}) -- (\xi, {exp(\xi)});}
          \temp
        }
    \end{axis}
  \end{tikzpicture}
  \caption{The 1st-order approximation $\EU{x}=1+x$.}
  \label{fig:first_order_approx_exp}
\end{figure}
