\section{Matrices}
In the previous section we described linear transformations in a rather abstract way: what they are, how they behave qualitatively and how they look like in 2- and 3-dimensions. In this section we introduce a numerical method of representing linear transformations: matrices.

\subsection{Linear transformation of basis vectors}
Recall that any vector $\vec{v}\in\Rs{n}$ can be written as a linear combination of basis vectors $\vec{b}_{1}, \vec{b}_{2}, \dots, \vec{b}_{n}$:
\begin{equation}
	\vec{v} = \sum\limits_{i=1}^{n}\alpha_{i}\vec{b}_{i} = \alpha_{1}\vec{b}_{1} + \alpha_{2}\vec{b}_{2} + \cdots + \alpha_{n}\vec{b}_{n}.
\end{equation}

Applying a linear transformation $T$ on $\vec{v}$ yields, using the properties of linear transformations,
\begin{align}
	T\left(\vec{v}\right) &= T\left(\alpha_{1}\vec{b}_{1} + \alpha_{2}\vec{b}_{2} + \cdots + \alpha_{n}\vec{b}_{n}\right)\nonumber\\
	\tikz[baseline=-0.5ex]{\draw[-stealth, xred] (0,0) -- (1,0) node[pos=-0.1, anchor=east] {additivity}}
						  &= T\left(\alpha_{1}\vec{b}_{1}\right) + T\left(\alpha_{2}\vec{b}_{2}\right) + \cdots + T\left(\alpha_{n}\vec{b}_{n}\right)\nonumber\\
    \tikz[baseline=-0.5ex]{\draw[-stealth, xblue] (0,0) -- (1,0) node[pos=-0.1, anchor=east] {scalability}}
						  &= \alpha_{1}T\left(\vec{b}_{1}\right) + \alpha_{2}T\left(\vec{b}_{2}\right) + \cdots + \alpha_{n}T\left(\vec{b}_{n}\right).
	\label{eq:transfom_by_basis}
\end{align}

This result is pretty neat: it means that by knowing how a linear transformation $T$ changes the basis vectors, we know exactly how any vector is transformed by $T$. This true for any basis, and thus specifically to the standard basis, where the coefficients $\alpha_{1},\alpha_{2},\dots,\alpha_{n}$ are actually the components of the vector, i.e. $v_{1},v_{2},\dots,v_{n}$. Thus in the standard basis:
\begin{equation}
	T\left(\vec{v}\right) = v_{1}T\left(\eb{1}\right) + v_{2}T\left(\eb{2}\right) + \cdots + v_{n}T\left(\eb{n}\right).
\end{equation}

\begin{example}{Vector transformation via a basis}{}
	Applying the transformation $T:\Rs{3}\to\Rs{3}$, defined as
	\[
		T\left(\colvec{x;y;z}\right)=\colvec{x+y-2z;2x+z;-x-y-z}
	\]
	on the vector $\vec{v}=\colvec{2;-1;3}$ yields the following vector:
	\[
		T\left(\vec{v}\right) = T\left(\colvec{2;-1;3}\right) = \colvec{2+(-1)-2\cdot3;2\cdot2+3;-2-(-1)-3} = \colvec{2-1-6;4+3;-2+1-3} = \colvec{-5;7;-4}.
	\]

	Now, let us apply $T$ first to the three standard basis vectors $\hat{x},\hat{y},\hat{z}$:
	\begin{align*}
		T\left( \hat{x} \right) &= T\left(\colvec{1;0;0}\right) = \colvec{1+0-2\cdot0;2\cdot1+0;-1-0-0} = \colvec{1;2;-1},\\
		T\left( \hat{y} \right) &= T\left(\colvec{0;1;0}\right) = \colvec{0+1-2\cdot0;2\cdot0+0;-0-1-0} = \colvec{1;0;-1},\\
		T\left( \hat{z} \right) &= T\left(\colvec{0;0;1}\right) = \colvec{0+0-2\cdot1;2\cdot0+1;-0-0-1} = \colvec{-2;1;-1}.
	\end{align*}

	Taking these results and applying \autoref{eq:transfom_by_basis} yields
	\begin{align*}
		T\left( \vec{v} \right) &= 2T \left( \hat{x} \right) -T \left( \hat{y} \right) + 3T \left( \hat{z} \right)\\
								&= 2\colvec{1;2;-1} - \colvec{1;0;-1} + 3\colvec{-2;1;-1}\\
								&= \colvec{2;4;-2} - \colvec{1;0;-1} + \colvec{-6;3;-3}\\
								&= \colvec{2-1-6;4-0+3;-2-(-1)+(-3)}\\
								&= \colvec{-5;7;-4},
	\end{align*}
	which is indeed what we got when we applied $T$ directly to $\vec{v}$.
\end{example}

\subsection{From transformations to matrices}
The most general linear transformation $T:\Rs{2}\to\Rs{2}$ has the following form:
\begin{equation}
	T \left( \colvec{x;y} \right) = \colvec{ax+by;cx+dy},
	\label{eq:generic_R2_LT}
\end{equation}
where $a,b,c,d\in\mathbb{R}$. If we apply this transformation to $\hat{x}$ and $\hat{y}$ we get, respectively,
\begin{equation}
	T \left( \hat{x} \right) = \colvec{a;c},\quad T \left( \hat{y} \right) = \colvec{b;d}.
	\label{eq:}
\end{equation}
We can now collect these two vectors to form a new structure, which we call a \emph{matrix} (in this specific casr a $2\times2$ matrix):
\begin{equation}
	A = \begin{bNiceMatrix} a&b\\c&d \end{bNiceMatrix}.
	\label{eq:matrix}
\end{equation}

We then define the product of $M$ with a vector $\vec{v}=\colvec{x;y}$ to yield $T \left( \vec{v} \right)$, i.e.
\begin{equation}
	A\vec{v} = \begin{bNiceMatrix} a&b\\c&d \end{bNiceMatrix} \cdot\colvec{x;y} = \colvec{ax+by;cx+dy}.
	\label{eq:matrix_vector_product}
\end{equation}
This defintion can be re-written as following:
\begin{equation}
	A\vec{v} = \begin{bNiceMatrix} a&b\\c&d \end{bNiceMatrix} \cdot\colvec{x;y} = \colvec{A_{1}\cdot\vec{v};A_{2}\cdot\vec{v}},
	\label{eq:matrix_vector_product_as_dot_product}
\end{equation}
i.e. the $i$-th component of the resulting vector is the scalar product of the $i$-th \textbf{row} of the matrix with the vector $\vec{v}$.

\begin{example}{Matrix-vector product}{}
	Some matrix-vector products:

	\begin{align*}
		\begin{bNiceMatrix}
			1 & -2 \\
			0 & 5
		\end{bNiceMatrix}\colvec{-3;2} &= \colvec{1\cdot(-3) + (-2)\cdot2;0\cdot(-3)+5\cdot2} = \colvec{-7;10},\\[5mm]
		\begin{bNiceMatrix}
			1 & 2 \\
			1 & 2
		\end{bNiceMatrix}\colvec{5;-4} &= \colvec{1\cdot5+2\cdot(-4);1\cdot5+2\cdot(-4)} = \colvec{-3;-3},\\[5mm]
		\begin{bNiceMatrix}
			1 & 0 \\
			0 & 2
		\end{bNiceMatrix}\colvec{2;-2} &= \colvec{2\cdot2+0\cdot(-2);0\cdot2+2\cdot(-2)} = \colvec{4;-4}.
	\end{align*}
\end{example}

\begin{challenge}{Proof of linearity}{}
	Prove that the transformation $T$ in \autoref{eq:generic_R2_LT} is indeed linear.
\end{challenge}

The most general form of a linear transformation is $T:\Rs{n}\to\Rs{m}$, i.e. a transformation which takes $n$-dimensional vectors as input and returns $m$-dimensional vectors as output:
\begin{equation}
	T \left( \colvec{\tikzmark{N}x_{1};x_{2};\vdots;x_{n}} \right) = \colvec{
		\Ma{1}{1}x_{1}+\Ma{1}{2}x_{2}+\cdots+\Ma{1}{n}x_{n};
		\Ma{2}{1}x_{1}+\Ma{2}{2}x_{2}+\cdots+\Ma{2}{n}x_{n}\tikzmark{M};
		\vdots;
		\Ma{m}{1}x_{1}+\Ma{m}{2}x_{2}+\cdots+\Ma{m}{n}x_{n}
	},
	\label{eq:}
\end{equation}
\begin{tikzpicture}[overlay, remember picture]
	\node[xblue] (Ntxt) at ($(pic cs:N)+(-1.5cm,-2mm)$) {$\Rs{n}\ni$};
	\draw[-stealth, xblue] (Ntxt) to [out=45, in=90] ($(pic cs:N)+(1mm,2.5mm)$);
	\node[xred] (Mtxt) at ($(pic cs:M)+(2.5cm,5mm)$) {$\in\Rs{m}$};
	\draw[-stealth, xred] (Mtxt) to [out=180, in=0] ($(pic cs:M)+(2.5mm,0)$);
\end{tikzpicture}

where $\Ma{i}{j}\in\mathbb{R},\ \textcolor{xred}{i}=1,2,3,\dots,m$ and $\textcolor{xblue}{j}=1,2,3,\dots,n$.

\begin{challenge}{Proof of linearity}{}
	Prove that the above transformation $T$ is indeed linear.
\end{challenge}

Respectively, we define an $\textcolor{xred}{m}\times \textcolor{xblue}{n}$ matrix (\textcolor{xred}{$m$} rows by \textcolor{xblue}{$n$} columns) by collecting all the coefficients $\Ma{i}{j}$ into a single structure:
\begin{equation}
	A =
	\begin{bNiceMatrix}
		\Ma{1}{1} & \Ma{1}{2} & \cdots & \Ma{1}{n}\\
		\Ma{2}{1} & \Ma{2}{2} & \cdots & \Ma{2}{n}\\
		\vdots & \vdots & \Ddots & \vdots\\
		\Ma{m}{1} & \Ma{m}{2} & \cdots & \Ma{m}{n}
	\end{bNiceMatrix}. 
	\label{eq:mxn_matrix}
\end{equation}
The product $M\vec{v}$ (where $\vec{v}\in\Rs{n}$) is then defined as
\begin{equation}
	A\vec{v} =
	\begin{bNiceMatrix}
		\Ma{1}{1} & \Ma{1}{2} & \cdots & \Ma{1}{n}\\
		\Ma{2}{1} & \Ma{2}{2} & \cdots & \Ma{2}{n}\\
		\vdots & \vdots & \Ddots & \vdots\\
		\Ma{m}{1} & \Ma{m}{2} & \cdots & \Ma{m}{n}
	\end{bNiceMatrix}\colvec{x_{1};x_{2};\vdots;x_{n}} = \colvec{
	\Ma{1}{1}x_{1}+\Ma{1}{2}x_{2}+\cdots+\Ma{1}{n}x_{n};
	\Ma{2}{1}x_{1}+\Ma{2}{2}x_{2}+\cdots+\Ma{2}{n}x_{n};
	\vdots;
	\Ma{m}{1}x_{1}+\Ma{m}{2}x_{2}+\cdots+\Ma{m}{n}x_{n}
	}.
	\label{eq:}
\end{equation}
Again, note that the $i$-th component of the resulting vector is the scalar product $A_{i}\cdot\vec{v}$.

\begin{note}{When is a matrix-vector product defined}{}
	In order for a matrix-vector product to be defined, the vector must be of the same dimension as the number of \textbf{columns} in the matrix - i.e. given an $a\times b$ matrix, a vector must be $b$-dimensional for the product to be defined.
\end{note}

\begin{example}{Some matrix-vector products}{}
	\blindtext[2]
\end{example}

The structure of an $m\times n$ matrix $A$ has a nice property: given that the transformation in represented in some basis $B=\left\{ \vec{b}_{1},\vec{b}_{2},\dots,\vec{b}_{n} \right\}$, the $i$-th column of the matrix always shows how $\vec{b}_{i}$ is transformed by the product $A\vec{b}_{n}$. This is easy to see in the case of the standard basis, which we anyway use througout this chapter:

\vspace{1cm}
\begin{equation*}
	\setlength{\arraycolsep}{2.7mm}
	A =
	\begin{bNiceMatrix}
		\tikzmark{A1}\Ma{1}{1} & \tikzmark{B1}\Ma{1}{2} & \cdots & \tikzmark{N1}\Ma{1}{n}\\
	    \Ma{2}{1} & \Ma{2}{2} & \cdots & \Ma{2}{n}\\
		\vdots & \vdots & \ddots & \vdots\\
		\Ma{m}{1}\tikzmark{A2} & \Ma{m}{2}\tikzmark{B2} & \cdots & \Ma{m}{n}\tikzmark{N2}
	\end{bNiceMatrix}.
\end{equation*}
\tikzset{
	highlight/.style={thick, draw=#1, rounded corners, draw opacity=1, fill=#1, fill opacity=0.2},
	hltxt/.style={highlight=#1, draw opacity=1, text=black, text opacity=1, above, yshift=1.5cm},
	nrtxt/.style={black, opacity=1, text opacity=1},
	hlarrow/.style={-stealth, thick, #1},
}
\tikz[overlay, remember picture, blend mode=multiply]{
	\draw[highlight={xgreen}]  ($(pic cs:A1)+(-2pt,7pt)$) rectangle node[hltxt={xgreen} ](Atxt){$T \left( \eb{1} \right)$}($(pic cs:A2)+(2pt,-5pt)$);
	\draw[highlight={xpurple}] ($(pic cs:B1)+(-2pt,7pt)$) rectangle node[hltxt={xpurple}](Btxt){$T \left( \eb{2} \right)$}($(pic cs:B2)+(2pt,-5pt)$);
	\draw[highlight={xorange}] ($(pic cs:N1)+(-2pt,7pt)$) rectangle node[hltxt={xorange}](Ntxt){$T \left( \eb{n} \right)$}($(pic cs:N2)+(2pt,-5pt)$);

	\draw[hlarrow={xgreen}]  (Atxt.south) -- ++(0,-5mm);
	\draw[hlarrow={xpurple}] (Btxt.south) -- ++(0,-5mm);
	\draw[hlarrow={xorange}] (Ntxt.south) -- ++(0,-5mm);
}

\begin{example}{Matrices}{}
	The product of the following matrix $A$ with each of the vectors $\eb{1},\eb{2},\eb{3}$ (i.e. $\hat{x},\hat{y}$ and $\hat{z}$, respectively) returns the respective column of the matrix:
	\begin{align*}
		A\eb{1}=
		\begin{bNiceMatrix}
			 1 & 2 & 0\\
			-1 & 3 & 4\\
			 0 & 1 & 3\\
		 \end{bNiceMatrix}\colvec{1;0;0} &= \colvec{1\cdot1+2\cdot0+0\cdot0;-1\cdot1+3\cdot0+4\cdot0;0\cdot1+1\cdot0+3\cdot0} = \colvec{1;-1;0},\\[3mm]
		A\eb{2}=
		\begin{bNiceMatrix}
			 1 & 2 & 0\\
			-1 & 3 & 4\\
			 0 & 1 & 3\\
		\end{bNiceMatrix}\colvec{0;1;0} &= \colvec{1\cdot0+2\cdot1+0\cdot0;-1\cdot0+3\cdot1+4\cdot0;0\cdot0+1\cdot1+3\cdot0} = \colvec{2;3;1},\\[3mm]
		A\eb{3}=
		\begin{bNiceMatrix}
			 1 & 2 & 0\\
			-1 & 3 & 4\\
			 0 & 1 & 3\\
		\end{bNiceMatrix}\colvec{0;0;1} &= \colvec{1\cdot0+2\cdot0+0\cdot1;-1\cdot0+3\cdot0+4\cdot1;0\cdot0+1\cdot0+3\cdot1} = \colvec{0;4;3}.
	\end{align*}
\end{example}

\subsection{Matrix representation of the basic linear transformations (2D)}
We can now represent all of the basic linear transformations in $\Rs{2}$ mentioned in the previous section (\autoref{fig:basicLinearTrans}) as $2\times2$ matrices. We do this by observing how the basis vectors $\hat{x}$ and $\hat{y}$ change after the application of each transformation.

\begin{descitemize}
	\item[Identity] both basis vectors remain the same: $\colvec{1;0}\to\colvec{1;0},\ \colvec{0;1}\to\colvec{0;1}$. Therefore the matrix $I$ representing the identity transformation is
		\begin{equation}
			I = \begin{bNiceMatrix} 1&0 \\ 0&1 \end{bNiceMatrix}.
		\end{equation}

	\item[Scaling by $\bm{s}$ in the $\bm{x}$-direction] the basis vector $\hat{x}$ is streched by $s$: $\colvec{1;0}\to\colvec{s;0}$. The basis vector $\hat{y}=\colvec{0;1}$ stays the same. Therefore the matrix $S_{x}$ representing the transformation is
		\begin{equation}
			S_{x} = \begin{bNiceMatrix} s&0 \\ 0&1 \end{bNiceMatrix}.
			\label{eq:}
		\end{equation}
	
	\item[Scaling by $\bm{s}$ in the $\bm{y}$-direction] much like with $S_{x}$, now the basis vector $\hat{y}$ is the one getting streched, by $\beta$: $\colvec{0;1}\to\colvec{0;s}$. The basis vector $\hat{x}=\colvec{1;0}$ stays the same. Therefore the matrix $S_{y}$ representing the transformation is
		\begin{equation}
			S_{y} = \begin{bNiceMatrix} 1&0 \\ 0&s \end{bNiceMatrix}.
			\label{eq:}
		\end{equation}

	\item[Rotating by $\bm{\theta}$ counter-clockwise about the origin] \autoref{fig:rotationT} shows how do $\hat{x}$ and $\hat{y}$ transformed by the rotation. In the case of $\hat{x}$, the resulting vector is $R_{\theta} \left( \hat{x} \right)=\colvec{\cos(\theta),\sin(\theta)}$, since thiese are the respective sides of a right triangle of hypotenous $1$ and angle $\theta$. The components of $R_{\theta}\left(\hat{y}\right)$ can be calculated by rotating $\hat{x}$ by $\theta+\frac{\pi}{2}$ ($\theta+\ang{90}$): $\cos \left( \theta+\frac{\pi}{2} \right) = -\sin(\theta)$, and $\sin \left( \theta+\frac{\pi}{2} \right) = \cos \left( \theta \right)$. Therefore we get
		\begin{equation}
			\colvec{1;0} \to \colvec{\cos(\theta);\sin(\theta)},\ \colvec{0;1} \to \colvec{-\sin(\theta);\cos(\theta)}.
			\label{eq:}
		\end{equation}

		Altogether the rotation matrix $R_{\theta}$ is
		\begin{equation}
			R_{\theta} = \begin{bNiceMatrix} \cos(\theta)&-\sin(\theta) \\ \sin(\theta)&\cos(\theta) \end{bNiceMatrix}.
			\label{eq:2D_rotation_matrix}
		\end{equation}

		\begin{figure}
			\centering
			\begin{tikzpicture}
				\begin{axis}[
					vector plane,
					width=10cm, height=10cm,
					xmin=-1.3, xmax=1.3,
					ymin=-1.3, ymax=1.3,
					xtick={-1,0,1},
					ytick={-1,0,1},
					yticklabel pos=right,
					yticklabel style={anchor=west},
				]
				\pgfmathsetmacro{\t}{30};
				\draw[black!20] (1,0) arc (0:360:1);
				\tikzset{point/.style={circle, fill=#1, inner sep=0pt, minimum size=3pt}}

				% x
				\draw[vector, xred] (0,0) -- (1,0) node[midway, below] {$\hat{x}$};
				\draw[vector, xred, dashed] (0,0) -- ({cos(\t)},{sin(\t)}) node[midway, above, rotate=\t] {$R_{\theta} \left( \hat{x} \right)$};
				\fill[xpurple, opacity=0.15] (0,0) -- (1,0) arc (0:\t:1) -- cycle;
				\draw[vector, xpurple, dashed] (1,0) arc (0:\t:1) node[point={xred}] (rx) {};
				\node[text=xpurple] at ({1.1*cos(\t/2)},{1.1*sin(\t/2)}) {$\theta$};
				
				% y
				\draw[vector, xblue] (0,0) -- (0,1) node[midway, right] {$\hat{y}$};
				\draw[vector, xblue, dashed] (0,0) -- ({-sin(\t)},{cos(\t)}) node[midway, below, rotate={\t-90}] {$R_{\theta} \left( \hat{y} \right)$};
				\fill[xpurple, opacity=0.15] (0,0) -- (0,1) arc (90:{90+\t}:1) -- cycle;
				\draw[vector, xpurple, dashed] (0,1) arc (90:{90+\t}:1) node[point={xblue}] (ry) {};
				\node[text=xpurple] at ({-1.1*sin(\t/2)},{1.1*cos(\t/2)}) {$\theta$};
				\end{axis}
				\node[xred, anchor=west, yshift=5pt]  at (rx) {$\left(  \Ctrig,\Strig \right)$};
				\node[xblue, anchor=east, xshift=-4pt] at (ry) {$\left( -\Strig,\Ctrig \right)$};
			\end{tikzpicture}
			\caption{Rotation of $\textcolor{xred}{\hat{x}}$ and $\textcolor{xblue}{\hat{y}}$ by an angle $\textcolor{xpurple}{\theta}$ counter-clockwise about the origin. The notations $\Ctrig,\Strig$ stand for $\cos(\textcolor{xpurple}{\theta})$ and $\sin(\textcolor{xpurple}{\theta})$, respectively.}
			\label{fig:rotationT}
		\end{figure}
	
	\item[Skew by $\bm{k}$ in the $\bm{x}$-direction] what differentiates this transformation from scaling in the $x$-direction is that a skew changes only $\hat{y}$ by adding to it some horizontal displacement $\vec{K}=k\hat{x}$ (see \autoref{fig:skew_in_x}). Therefore $\hat{x}$ remains the same while $\hat{y}$ is transformed as $\hat{y}\to\hat{y}+\vec{k}=\hat{y}+k\hat{x}=\colvec{0;1}+\colvec{k;0}=\colvec{k;1}$, and altogether the matrix is
		\begin{equation}
			K_{x} = \begin{bNiceMatrix} 1&k \\ 0&1 \end{bNiceMatrix}.
			\label{eq:}
		\end{equation}
		
		\begin{figure}
			\centering
			\begin{tikzpicture}
				\begin{axis}[
					vector plane,
					width=10cm, height=10cm,
					xmin=-1.3, xmax=1.3,
					ymin=-1.3, ymax=1.3,
					ticks=none,
				]
				\draw[vector, xred]  (0,0) -- (1,0) node[midway, below] {$\hat{x}, K_{x}\left(\hat{x}\right)$};
				\draw[vector, xblue] (0,0) -- (0,1) node[midway, right] {$\hat{y}$};
				\draw[vector, xblue, dashed] (0,0) -- (0.5,1) node[midway, right] {$K_{x}\left( \hat{y} \right)$};
				\draw[vector, xpurple, dashed] (0,1) -- (0.5,1) node [midway, above] {$\vec{k}=k\hat{x}$};
				\end{axis}
			\end{tikzpicture}
			\caption{Skew in the $x$-direction.}
			\label{fig:skew_in_x}
		\end{figure}

	\item[Skew by $\bm{k}$ in the $\bm{y}$-direction] same idea, except the roles of the axes are reveresed:
		\[
			\colvec{1;0}\to\colvec{1;k},\ \colvec{0;1}\to\colvec{0;1}.
		\]
		Thus the matrix is
		\begin{equation}
			K_{y} = \begin{bNiceMatrix} 1&0 \\ k&1 \end{bNiceMatrix}.
			\label{eq:}
		\end{equation}

	\item[Reflections across a line going through the origin] in the case of reflections across the $x$-axis, $\hat{x}$ stays the same, while $\hat{y}$ is flipped (see \autoref{fig:ref_x_axis}), i.e. $\colvec{0;1}\to-\colvec{0;1}=\colvec{0;-1}$. Therefore the matrix is
		\begin{equation}
			\Refl_{x} = \begin{bNiceMatrix} 1&0 \\ 0&-1 \end{bNiceMatrix}.
		\end{equation}
		
		Similarily, a reflection across the $y$-axis flipps $\hat{x}$ while keeping $\hat{y}$ the same (see \autoref{fig:ref_y_axis}), i.e.
		\begin{equation}
			\Refl_{y} = \begin{bNiceMatrix} -1&0 \\ 0&1 \end{bNiceMatrix}. 
		\end{equation}
		
		Another special case of these kinds of reflections is done across the line rotated by $\frac{\pi}{4}=\ang{45}$ relative to the $x$-axis, i.e the line $y=x$. In this case $\hat{x}$ and $\hat{y}$ are swapped, giving
		\begin{equation}
			\Refl_{\frac{\pi}{4}} = \begin{bNiceMatrix} 0&1 \\ 1&0 \end{bNiceMatrix}. 
		\end{equation}

		The most general reflection is made across a line of angle $\theta$ relative to the $x$-axis (see \autoref{fig:ref_line}):
		\begin{equation}
			\Refl_{\theta} = \begin{bNiceMatrix} \cos \left( 2\theta \right) & \sin \left( 2\theta \right) \\ \sin \left( 2\theta \right) & -\cos \left( 2\theta \right) \end{bNiceMatrix}.
		\end{equation}
		A way to calculate this matrix will be shown later in the chapter.

		We can translate the matrix to be based on the slope $m$ of the line instead of its angle $\theta$ relative to the $x$-axis by using the relation $m=\tan\left(\theta\right)$ and the two trigonomentric identities for double angles (\autoref{eq:tan_double_angles}):
		\begin{align*}
			\begin{bNiceMatrix} \cos \left( 2\theta \right) & \sin \left( 2\theta \right) \\ \sin \left( 2\theta \right) & -\cos \left( 2\theta \right) \end{bNiceMatrix} &= \begin{bNiceMatrix} \frac{1-\tan^{2} \left( \theta \right) }{1+\tan^{2} \left( \theta \right) } & \frac{2\tan \left( \theta \right) }{1+\tan^{2} \left( \theta \right) } \\ \frac{2\tan \left( \theta \right) }{1+\tan^{2} \left( \theta \right) } & \frac{\tan^{2} \left( \theta \right)-1 }{1+\tan^{2} \left( \theta \right) } \end{bNiceMatrix}\\
														&= \frac{1}{1+\tan^{2} \left( \theta \right)}\begin{bNiceMatrix} 1-\tan^{2} \left( \theta \right) & 2\tan \left( \theta \right) \\ 2\tan \left( \theta \right) & \tan^{2} \left( \theta \right) -1  \end{bNiceMatrix}\\
														&= \frac{1}{1+m^{2}} \begin{bNiceMatrix} 1-m^{2} & 2m \\ 2m & m^{2}-1 \end{bNiceMatrix}.
		\end{align*}	

		\begin{figure}
			\centering
			\begin{subfigure}[c]{0.45\textwidth}
			\begin{center}
				\begin{tikzpicture}
					\begin{axis}[
						vector plane,
						width=8cm, height=8cm,
						xmin=-1.5, xmax=1.5,
						ymin=-1.5, ymax=1.5,
						ticks=none,
					]
					\draw[vector, xred]  (0,0) -- (1,0) node[below] {$\hat{x},\ \Refl_{x}\left(\hat{x}\right)$};
					\draw[vector, xblue] (0,0) -- (0,1) node[right] {$\hat{y}$};
					\draw[vector, xblue, dashed] (0,0) -- (0,-1) node[right] {$\Refl_{x}\left(\hat{y}\right)$};
					\end{axis}
				\end{tikzpicture}	
			\end{center}
			\caption{Reflection across the $x$-axis.}
			\label{fig:ref_x_axis}
			\end{subfigure}
			\hfill
			\begin{subfigure}[c]{0.45\textwidth}
			\begin{center}
				\begin{tikzpicture}
					\begin{axis}[
						vector plane,
						width=8cm, height=8cm,
						xmin=-1.5, xmax=1.5,
						ymin=-1.5, ymax=1.5,
						ticks=none,
					]
					\draw[vector, xred]  (0,0) -- (1,0) node[below] {$\hat{x}$};
					\draw[vector, xred, dashed] (0,0) -- (-1,0) node[below] {$\Refl_{y}\left(\hat{x}\right)$};
					\draw[vector, xblue] (0,0) -- (0,1) node[right] {$\hat{y},\ \Refl_{y}\left(\hat{y}\right)$};
					\end{axis}
				\end{tikzpicture}	
			\end{center}
			\caption{Reflection across the $y$-axis.}
			\label{fig:ref_y_axis}
			\end{subfigure}
			\begin{subfigure}[c]{0.45\textwidth}
			\begin{center}
				\begin{tikzpicture}
					\begin{axis}[
						vector plane,
						width=8cm, height=8cm,
						xmin=-1.5, xmax=1.5,
						ymin=-1.5, ymax=1.5,
						ticks=none,
					]
					% original vectors
					\draw[vector, xred]  (0,0) -- (1,0) node[below] {$\hat{x}$};
					\draw[vector, xblue] (0,0) -- (0,1) node[right] {$\hat{y}$};
					
					% reflection line
					\draw[thick, black!75, dashed] (-1.5,-0.5) -- (1.5,0.5);

					% reflected vectors
					\draw[vector, xred, dashed]  (0,0) -- (0.8,0.6) node[below, anchor=west, yshift=5pt] {$\Refl_{\theta}\left(\hat{x}\right)$};
					\draw[vector, xblue, dashed, anchor=west] (0,0) -- (0.6,-0.8) node[right] {$\Refl_{\theta}\left(\hat{y}\right)$};

					% angles
					\fill[xpurple, opacity=0.2] (0,0) -- (0.5,0) arc (0:18.435:0.5) node (A) {} -- cycle;
					\fill[xgreen, opacity=0.2]  (0,0) -- (A) arc (18.435:36.87:0.5) -- (0,0);
					\fill[xpurple, opacity=0.2] (0,0) -- (0,0.5) arc (90:198.435:0.5) node (B) {} -- cycle;
					\fill[xgreen, opacity=0.2]  (0,0) -- (B) arc (198.435:306.87:0.5) -- (0,0);
					\end{axis}
				\end{tikzpicture}	
			\end{center}
			\caption{Reflection across a line going through the origin. Notice how in both cases the purple and green angles are the same: this shows that both $\hat{x}$ and $\hat{y}$ are reflected across the line.}
			\label{fig:ref_line}
			\end{subfigure}
			\caption{Reflections across different lines going through the origin.}
			\label{fig:reflections}
		\end{figure}
		
	\item[Reflection across the origin] in this case both $\hat{x}$ and $\hat{y}$ are flipped, i.e.
		\[
			\colvec{1;0}\to\colvec{-1;0},\ \colvec{0;1}\to\colvec{0;-1},
		\]
		and the matrix is essentially a rotation by $\pi$ ($\ang{180}$) around the origin:
		\begin{equation}
			R = \begin{bNiceMatrix} -1&0 \\ 0&-1 \end{bNiceMatrix}.
			\label{eq:}
		\end{equation}
\end{descitemize}

Table \autoref{tab:matrix_basic_LTs} summarizes all the matrices of the basic linear transformations.

\begin{longtable}{lcccc}
	% !!! vvv MUST FIND WHY THESE DON'T WORK vvv !!! %
	% \caption{my caption}\\
	% \label{tab:matrix_basic_LTs}
	% !!! ^^^ THESE TWO LINES ^^^ !!! %
	\toprule
	Transformation & Trans Tapir & $T \left( \hat{x} \right)$ & $T \left( \hat{y} \right)$ & Matrix\\
	\midrule
	Identity & \tikz[baseline=-0.5ex]{\tapirTransComp{1}{0}{0}{1}{0}{0}{}} & $\colvec{1;0}$ & $\colvec{0;1}$ & $\begin{bNiceMatrix} 1&0 \\ 0&1 \end{bNiceMatrix}$\\
	Scale in $x$ & \tikz[baseline=-0.5ex]{\tapirTransComp{1.3}{0}{0}{1}{0}{0}{}} & $\colvec{s;0}$ & $\colvec{0;1}$ & $\begin{bNiceMatrix} s&0 \\ 0&1 \end{bNiceMatrix}$\\
	Scale in $y$ & \tikz[baseline=-0.5ex]{\tapirTransComp{1}{0}{0}{1.4}{0}{0}{}} & $\colvec{1;0}$ & $\colvec{0;s}$ & $\begin{bNiceMatrix} 1&0 \\ 0&s \end{bNiceMatrix}$\\
	Rotation & \tikz[baseline=-0.5ex]{\tapirTransComp{0.866}{0.5}{-0.5}{0.866}{0}{0}{}} & $\colvec{\Ctrig;-\Strig}$ & $\colvec{\Strig;\Ctrig}$ & $\begin{bNiceMatrix} \Ctrig & -\Strig \\ \Strig & \Ctrig \end{bNiceMatrix}$\\
	Skew in $x$ & \tikz[baseline=-0.5ex]{\tapirTransComp{1}{0}{0.5}{1}{0}{0}{}} & $\colvec{1;0}$ & $\colvec{k;1}$ & $\begin{bNiceMatrix} 1&0 \\ k&1 \end{bNiceMatrix}$\\
	Skew in $y$ & \tikz[baseline=-0.5ex]{\tapirTransComp{1}{0.35}{0}{1}{0}{0}{}} & $\colvec{1;k}$ & $\colvec{0;1}$ & $\begin{bNiceMatrix} 1&k \\ 0&1 \end{bNiceMatrix}$\\
	Reflection by $x$ & \tikz[baseline=-0.5ex]{\tapirTransComp{1}{0}{0}{-1}{0}{0}{}} & $\colvec{1;0}$ & $\colvec{0;-1}$ & $\begin{bNiceMatrix} 1&0 \\ 0&-1 \end{bNiceMatrix}$\\
	Reflection by $y$ & \tikz[baseline=-0.5ex]{\tapirTransComp{-1}{0}{0}{1}{0}{0}{}} & $\colvec{-1;0}$ & $\colvec{0;1}$ & $\begin{bNiceMatrix} -1&0 \\ 0&1 \end{bNiceMatrix}$\\
	Reflection by line & \tikz[baseline=-0.5ex]{\tapirTransComp{0.882}{0.471}{0.471}{-0.882}{0}{0}{};\draw[very thick, dashed, xpurple](-2,-0.5)--(2,0.5)node[pos=-0.05, anchor=east] {$y=mx$}} & $\colvec{\Ctrig_{2};\Strig_{2}}$ & $\colvec{\Strig_{2};-\Ctrig_{2}}$ & $\begin{bNiceMatrix} \Ctrig_{2}&\Strig_{2} \\ \Strig_{2}&-\Ctrig_{2} \end{bNiceMatrix}$\\
	Reflection about origin & \tikz[baseline=-0.5ex]{\tapirTransComp{-1}{0}{0}{-1}{0}{0}{}} & $\colvec{-1;0}$ & $\colvec{0;-1}$ & $\begin{bNiceMatrix} -1&0 \\ 0&-1 \end{bNiceMatrix}$\\
	\bottomrule
\end{longtable}

\subsection{Matrix representation of the basic linear transformations (3D)}
In 3-dimensions, the respective matrices are very similar. For example, the matrix for scaling by $\alpha$ in the $x$-direction, $\beta$ in the $y$-direction and $\gamma$ in the $z$-direction is
\begin{equation}
	S = 
	\begin{bNiceMatrix}
		\alpha & 0 & 0\\
		0 & \beta & 0\\
		0 & 0 & \gamma
	\end{bNiceMatrix}.
	\label{eq:3d_scale_matrix}
\end{equation}

As mentioned in the previous section, in 3-dimensions there are infinitely many rotations: the axis of rotation can be any line going through the origin (i.e. any vector except $\vec{0}$ can represent an axis of rotation). Let us start with constructing rotations around the three axes $x,y$ and $z$ first. When rotating around the $x$ axis it stays stationary, while the rotation itself is done in the $yz$-plane. This means that we can take the $2\times2$ rotation matrix (\autoref{eq:2D_rotation_matrix}) and expand it such that it affects only the $yz$-plane:

\vspace{2em}
\begin{equation}
	R^{x}_{\theta} =
	\begin{bNiceMatrix}
		\tikzmark{D1}1 & 0 & 0\\
		0 & \tikzmark{E1} \cos \left( \theta \right) & -\sin \left( \theta \right) \\
		0\tikzmark{D2} & \sin \left( \theta \right) & \cos \left( \theta \right)\tikzmark{E2}
	\end{bNiceMatrix}.
	\label{eq:rotation_matrix_x}
\end{equation}
\begin{tikzpicture}[overlay, remember picture, blend mode=multiply]
	\small
	\draw[highlight={xred}] ($(pic cs:D1)+(-4pt,9pt)$) rectangle node[hltxt={xred}, above right, anchor=east, xshift=-1cm] (Atxt) {$\hat{x}$ doesn't change} ($(pic cs:D2)+(4pt,-5pt)$);
	\draw[hlarrow={xred}] (Atxt.east) to [out=0, in=90] ($(pic cs:D1) + (3pt,10pt)$);
	\draw[highlight={xgreen}] ($(pic cs:E1)+(-4pt,9pt)$) rectangle node[hltxt={xgreen}, below left, anchor=west, yshift=-3cm, xshift=9mm] (Btxt) {2D rotation matrix} ($(pic cs:E2)+(4pt,-5pt)$);
	\draw[hlarrow={xgreen}] (Btxt.west) to [out=180, in=-90] ($(pic cs:E1) + (35pt,-20pt)$);
\end{tikzpicture}

\vspace{3em}
A graphical representation of the rotation can be seen in \autoref{fig:rotation_in_yz}.

\begin{figure}
	\centering
	\def\angThe{75}
	\def\angPhi{45}
	\tdplotsetmaincoords{\angThe}{\angPhi}
	\begin{tikzpicture}[tdplot_main_coords]
		\draw[stealth-, very thick] (-3,0,0) -- (0,0,0);
		\begin{scope}[canvas is yz plane at x=0]
			\fill[fill=xgreen, fill opacity=0.2] (-2,2) -- (2,2) -- (2,-2) -- (-2,-2) -- cycle;
			\draw[step=0.5, xdarkgreen!30] (-2,-2) grid (2,2);
			\draw[vector, xgreen] (-1,0) arc (180:350:1);
			\draw[vector, xgreen] (1,0) arc (0:170:1);
		\end{scope}
		\draw[stealth-stealth, very thick] (0,-3,0) -- (0,3,0) node[pos=1.05] {$y$};
		\draw[stealth-stealth, very thick] (0,0,-3) -- (0,0,3) node[pos=1.05] {$z$};
		\begin{scope}[canvas is yz plane at x=2]
			\draw[vector, xgreen] (-0.5,0) arc (180:350:0.5);
		\end{scope}
		\draw[-stealth, very thick] (0,0,0) -- (3,0,0) node[pos=1.05] {$x$};
		\begin{scope}[canvas is yz plane at x=2]
			\draw[vector, xgreen] (0.5,0) arc (0:170:0.5);
		\end{scope}
	\end{tikzpicture}
	\caption{In $\Rs{3}$, rotation around the $x$-axis is a rotation in the $yz$-plane (i.e. $x=0$).}
	\label{fig:rotation_in_yz}
\end{figure}

The rotation matrices around the $y$- and $z$-axes follow the same structure:
\begin{align}
	R^{y}_{\varphi} &=
		\begin{bNiceMatrix}
			\cos \left( \varphi \right) & 0 & \sin \left( \varphi \right)\\
			0 & 1 & 0 \\
			-\sin \left( \varphi \right) & 0 & \cos \left( \varphi \right)
		\end{bNiceMatrix},\\
	R^{z}_{\psi} &=
		\begin{bNiceMatrix}
			\cos \left( \psi \right) & -\sin \left( \psi \right) & 0\\
			\sin \left( \psi \right) & \cos \left( \psi \right)  & 0\\
			0 & 0 & 1
		\end{bNiceMatrix}.
	\label{eq:rotation_y_z}
\end{align}

\begin{note}{Direction of the $y$-axis}{}
	The signs of $\sin \left( \varphi \right)$ in $R^{y}_{\varphi}$ are flipped compared to $R^{x}_{\theta}$ and $R^{z}_{\psi}$, for the same reason a similar thing happens in the $y$-component of the cross product: it is due to the use of a right-handed system.
\end{note}

The most general rotation in $\Rs{3}$, i.e. around an axis represented by the unit vector $\hat{u}=\colvec{u_{x};u_{y};u_{z}}$ counter-clockwise by an angle $\theta$, is given in matrix form as
\begin{equation}
	R_{\theta}=
	\begin{bNiceMatrix}
		\cos \left( \theta \right) +u_{x}^{2}\left[1-\cos \left( \theta \right) \right] & u_{x}u_{y}\left[1-\cos \left( \theta \right) \right]-u_{z}\sin \left( \theta \right)  & u_{x}u_{z}\left[1-\cos \left( \theta \right) \right]+u_{y}\sin \left( \theta \right) \\
		u_{y}u_{x}\left[1-\cos \left( \theta \right) \right]+u_{z}\sin \left( \theta \right)  & \cos \left( \theta \right) +u_{y}^{2}\left[1-\cos \left( \theta \right) \right] & u_{y}u_{z}\left[1-\cos \left( \theta \right) \right]-u_{x}\sin \left( \theta \right) \\
		u_{z}u_{x}\left[1-\cos \left( \theta \right) \right]-u_{y}\sin \left( \theta \right)  & u_{z}u_{y}\left[1-\cos \left( \theta \right) \right]+u_{x}\sin \left( \theta \right)  & \cos \left( \theta \right) +u_{z}^{2}\left[1-\cos \left( \theta \right) \right]\end{bNiceMatrix}.
	\label{eq:}
\end{equation}
For the moment the derivation of this matrix is not presented.

TBW: REFLECTIONS IN 3D.

\subsection{Matrix operations}
An important operation that can be performed on a matrix is the \emph{transpose}: this operation "rotates" all rows of the matrix to columns, and wise-versa:
\begin{equation}
	\begin{bNiceMatrix}
		\Ma{1}{1} & \Ma{1}{2} & \cdots & \Ma{1}{n}\\
		\Ma{2}{1} & \Ma{2}{2} & \cdots & \Ma{2}{n}\\
		\vdots & \vdots & \Ddots & \vdots\\
		\Ma{m}{1} & \Ma{m}{2} & \cdots & \Ma{m}{n}
	\end{bNiceMatrix}
	\xrightarrow[] {\text{transpose}}
	\begin{bNiceMatrix}
		\Ma{1}{1} & \Ma{2}{1} & \cdots & \Ma{n}{1}\\
		\Ma{1}{2} & \Ma{2}{2} & \cdots & \Ma{n}{2}\\
		\vdots & \vdots & \Ddots & \vdots\\
		\Ma{1}{m} & \Ma{2}{m} & \cdots & \Ma{n}{m}
	\end{bNiceMatrix}.
	\label{eq:transpose}
\end{equation}
Mathematically, the transpose takes any element $\Ma{i}{j}$ of the matrix and exchanges its indeces, yielding $\Ma{j}{i}$. If the original matrix has dimensions $\rhl{m}\times \bhl{n}$, then the transposed matrix has dimensions $\rhl{n}\times \bhl{m}$. The notation for the transpose of a matrix $A$ is $A^{\top}$.

\begin{example}{Transposing matrices}{}
	The following presents three matrices each with its transpose. The elements in each matrix on the left hand side are highlighted column-wise, and these colors remain with the elements after the transpose. That way, the effect of the transpose is clear: columns in the original matrix become rows in the transposed matrix and vice-versa. In addition, the dimensions of each matrix are written below it.

	\begin{align*}
		\begin{bNiceMatrix}[name=T1]
			1 & 2 & 3\\
			4 & 5 & 6\\
			7 & 8 & 9\\
		\end{bNiceMatrix}^{\top} &=
		\begin{bNiceMatrix}[name=T2]
			1 & 4 & 7\\
			2 & 5 & 8\\
			3 & 6 & 9\\
		\end{bNiceMatrix}\\[10mm]
		\begin{bNiceMatrix}[name=T3]
			0 & 1 & -1\\
			2 & -3 & 5\\
		\end{bNiceMatrix}^{\top} &=
		\begin{bNiceMatrix}[name=T4]
			0  & 2\\
			1  & -3\\
			-1 & 5\\
		\end{bNiceMatrix}\\[10mm]
		\begin{bNiceMatrix}[name=T5]
			1\\
			2\\
			-1\\
			0\\
			7\\
			-4\\
		\end{bNiceMatrix}^{\top} &=
		\begin{bNiceMatrix}[name=T6]
			1 & 2 & -1 & 0 & 7 & -4\\
		\end{bNiceMatrix}
	\end{align*}
\begin{tikzpicture}[overlay, remember picture, blend mode=multiply, node distance=15pt]
	% ---- T1 ---- %
	\MatHL{(T1-1-1),(T1-2-1),(T1-3-1)}{xred!20}
	\MatHL{(T1-1-2),(T1-2-2),(T1-3-2)}{xorange!20}
	\MatHL{(T1-1-3),(T1-2-3),(T1-3-3)}{xgreen!20}
	\node[below of=T1-3-2] {$3\times3$};
	% ---- T2 ---- %
	\MatHL{(T2-1-1),(T2-1-2),(T2-1-3)}{xred!20}
	\MatHL{(T2-2-1),(T2-2-2),(T2-2-3)}{xorange!20}
	\MatHL{(T2-3-1),(T2-3-2),(T2-3-3)}{xgreen!20}
	\node[below of=T2-3-2] {$3\times3$};
	
	% ---- T3 ---- %
	\MatHL{(T3-1-1),(T3-2-1)}{xred!20}
	\MatHL{(T3-1-2),(T3-2-2)}{xorange!20}
	\MatHL{(T3-1-3),(T3-2-3)}{xgreen!20}
	\node[below of=T3-2-2] {$2\times3$};
	% ---- T4 ---- %
	\MatHL{(T4-1-1),(T4-1-2)}{xred!20}
	\MatHL{(T4-2-1),(T4-2-2)}{xorange!20}
	\MatHL{(T4-3-1),(T4-3-2)}{xgreen!20}
	\node[below of=T4-3-1, xshift=10pt] {$3\times2$};
	
	% ---- T5 ---- %
	\MatHL{(T5-1-1),(T5-2-1),(T5-3-1),(T5-4-1),(T5-5-1),(T5-6-1)}{xred!20}
	\node[below of=T5-6-1] {$6\times1$};
	% ---- T6 ---- %
	\MatHL{(T6-1-1),(T6-1-2),(T6-1-3),(T6-1-4),(T6-1-5),(T6-1-6)}{xred!20}
	\node[below of=T6-1-3, xshift=10pt] {$1\times6$};
\end{tikzpicture}
\end{example}

Since for the main diagonal elements of a matrix the row and column have equal indeces, the transpose operation does not affect their position in the matrix, i.e. $\Ma{i}{i}\xrightarrow[] {\text{transpose}}\Ma{i}{i}$. This means that $\tr{A}=\tr{A^{\top}}$. Also, diagonal matrices are not affected by a transpose. The transpose of a transposed matrix is the original matrix, i.e. $\left(A^{\top}\right)^{\top} = A$.

Much like vectors, a matrix can be scaled by a real number, and two matrices can be added together if their dimensions are identical. The rules for scaling a matrix by a scalar and the addition of two matrices are the same as with vectors, namely everything is dome element wise:
\begin{descitemize}
	\item[Scaling] given a matrix
		\[
			A = 
			\begin{bNiceMatrix}
				\Ma{1}{1} & \Ma{1}{2} & \cdots & \Ma{1}{n}\\
				\Ma{2}{1} & \Ma{2}{2} & \cdots & \Ma{2}{n}\\
				\vdots & \vdots & \Ddots & \vdots\\
				\Ma{m}{1} & \Ma{m}{2} & \cdots & \Ma{m}{n}
			\end{bNiceMatrix}
		\]
		and a scalar $\gamma\in\mathbb{R}$, their product is
		\begin{equation}
			\gamma A = 
			\begin{bNiceMatrix}
				\gamma\cdot\Ma{1}{1} & \gamma\cdot\Ma{1}{2} & \cdots & \gamma\cdot\Ma{1}{n}\\
				\gamma\cdot\Ma{2}{1} & \gamma\cdot\Ma{2}{2} & \cdots & \gamma\cdot\Ma{2}{n}\\
				\vdots & \vdots & \Ddots & \vdots\\
				\gamma\cdot\Ma{m}{1} & \gamma\cdot\Ma{m}{2} & \cdots & \gamma\cdot\Ma{m}{n}
			\end{bNiceMatrix}.
			\label{eq:matrix_scaling}
		\end{equation}

	\item[Addition] given two matrices,
		\[
			A = 
			\begin{bNiceMatrix}
				\Ma{1}{1} & \Ma{1}{2} & \cdots & \Ma{1}{n}\\
				\Ma{2}{1} & \Ma{2}{2} & \cdots & \Ma{2}{n}\\
				\vdots & \vdots & \Ddots & \vdots\\
				\Ma{m}{1} & \Ma{m}{2} & \cdots & \Ma{m}{n}
			\end{bNiceMatrix},\quad
			B = 
			\begin{bNiceMatrix}
				\Mb{1}{1} & \Mb{1}{2} & \cdots & \Mb{1}{n}\\
				\Mb{2}{1} & \Mb{2}{2} & \cdots & \Mb{2}{n}\\
				\vdots & \vdots & \Ddots & \vdots\\
				\Mb{m}{1} & \Mb{m}{2} & \cdots & \Mb{m}{n}
			\end{bNiceMatrix}, 
		\]
		their sum is
		\begin{equation}
			A+B = 
			\begin{bNiceMatrix}
				\Ma{1}{1}+\Mb{1}{1} & \Ma{1}{2}+\Mb{1}{2} & \cdots & \Ma{1}{n}+\Mb{1}{n}\\
				\Ma{2}{1}+\Mb{2}{1} & \Ma{2}{2}+\Mb{2}{2} & \cdots & \Ma{2}{n}+\Mb{2}{n}\\
				\vdots & \vdots & \Ddots & \vdots\\
				\Ma{m}{1}+\Mb{m}{1} & \Ma{m}{2}+\Mb{m}{2} & \cdots & \Ma{m}{n}+\Mb{m}{n}
			\end{bNiceMatrix}.
			\label{eq:}
		\end{equation}
\end{descitemize}

\begin{note}{Matrix addition}{}
	Since matrix addition is done \textbf{element wise} it is comutative, i.e. for any two $m\times n$ matrices $A$ and $B$,
	\[
		A+B = B+A.
	\]
\end{note}

\subsection{Types of matrices}
Any matrix $A$ which represents a transformation of the type $\Rs{n}\to\Rs{n}$ (i.e. from a space onto itself) has the same number of rows and columns (i.e. its dimension is $n\times n$):
\begin{equation}
	A =
	\begin{bNiceMatrix}
		\Ma{1}{1} & \Ma{1}{2} & \cdots & \Ma{1}{n}\\
		\Ma{2}{1} & \Ma{2}{2} & \cdots & \Ma{2}{n}\\
		\vdots & \vdots & \Ddots & \vdots\\
		\Ma{n}{1} & \Ma{n}{2} & \cdots & \Ma{n}{n}
	\end{bNiceMatrix}. 
	\label{eq:square_matrix}
\end{equation}

Due to their shape, such matrices are called \emph{square matrices}. The elements $\Ma{1}{1},\Ma{2}{2},\Ma{3}{3},\dots,\Ma{n}{n}$ of a square matrix jointly form its \emph{main diagonal} (also: \emph{principal diagonal}):

\vspace{1em}
\begin{equation}
	A =
	\begin{bNiceMatrix}[name=A_diag]
		\Ma{1}{1} & \Ma{1}{2} & \Ma{1}{3} & \cdots & \Ma{1}{n}\\
		\Ma{2}{1} & \Ma{2}{2} & \Ma{2}{3} & \cdots & \Ma{2}{n}\\
		\Ma{3}{1} & \Ma{3}{2} & \Ma{2}{3} & \cdots & \Ma{2}{n}\\
		\vdots & \vdots & \vdots & \Ddots & \vdots\\
		\Ma{n}{1} & \Ma{n}{2} & \Ma{n}{3} & \cdots & \Ma{n}{n}
	\end{bNiceMatrix}. 
	\label{eq:square_matrix_main_diag}
\end{equation}
\begin{tikzpicture}[overlay, remember picture, blend mode=multiply]
	\foreach \k in {1,...,3,5}{
		\node[fill=xgreen!25, rectangle, minimum width=13pt, minimum height=10pt] at (A_diag-\k-\k) {};
	}
\end{tikzpicture}

The sum of the main diagonal elements is called the \emph{trace} of the matrix:
\begin{equation}
	\tr \left( A \right) = \sum\limits_{i=1}^{n}\Ma{i}{i}.
	\label{eq:trace}
\end{equation}

\emph{Triangular matrices} are matrices in which the elements above or below the main diagonal are all zeros, e.g.

\begin{center}
	\def\bperc{25}
	\begin{tabular}{p{-1mm}cp{5mm}p{-1mm}c}
		$U=$ &
		$\begin{bmatrix}
			1 & 6 & 6 & -3 \\
			\textcolor{black!\bperc}{0} & 2 & 7 & 1 \\
			\textcolor{black!\bperc}{0} & \textcolor{black!\bperc}{0} & 3 & 5 \\
			\textcolor{black!\bperc}{0} & \textcolor{black!\bperc}{0} & \textcolor{black!\bperc}{0} & -4
		\end{bmatrix},$
			 & &
		$L=$ &
		$\begin{bmatrix}
			1 & \textcolor{black!\bperc}{0} & \textcolor{black!\bperc}{0} & \textcolor{black!\bperc}{0} \\
			\tikzmark{LT1} 2 & 3 & \textcolor{black!\bperc}{0} & \textcolor{black!\bperc}{0} \\ 
			5 & 1 & -5 & \textcolor{black!\bperc}{0} \\
			-4 & 1 & 2\tikzmark{LT2} & -3
		\end{bmatrix}.$
		\\[2.5em]
			 & upper triangular & & & lower triangular
	\end{tabular}
\end{center}

A somewhat formal way of defining the elements "above" the main diagonal is all elements $\Ma{i}{j}$ for which $j<i$. Similarily, when $j>i$ the element $\Ma{i}{j}$ is "below" the main diagonal. Note that the transpose of an upper triangular matrix is a lower triangular matrix and vice-versa.

\begin{challenge}{Upper/lower triangular matrices}{}
	Show that if $A$ is an upper triangular matrix then $A^{\top}$ is a lower triangular matrix, and if $B$ is a lower triangular matrix then $B^{\top}$ is an upper triangular matrix.
\end{challenge}

A \emph{diagonal matrix} $A$ is a matrix in which all the non-main diagonal elements, i.e. $\Ma{i}{j}$ where $\textcolor{xred}{i}\neq \textcolor{xblue}{j}$, equal zero. These matrices can be thought of as scaling matrices: each entry $\Ma{i}{i}$ tells us how the sapce is scaled in the $i$-th dimension.

\begin{example}{Diagonal matrices}{}
	Text.
\end{example}
As we saw in the cases of $\Rs{2}$ and $\Rs{3}$, diagonal matrices are \emph{scaling matrices}: each entry $a_{ii}$ tells us by how much space is scaled in the $i$-th direction.

A very important family of \textbf{square} matrices are the \emph{identity matrices}. These matrices have a unique structure: their main diagonal elements are all $1$, while the rest of the elements (the \emph{off-diagonal elements}) are all $0$:

\vspace{1em}
\begin{equation}
	I_{n} =
	\begin{bNiceMatrix}
		\tikzmark{I11} 1 & 0 & 0 & \cdots & 0\tikzmark{I1n}\\
		0 & 1 & 0 & \cdots & 0\\
		0 & 0 & 1 & \cdots & 0\\
		\vdots & \vdots & \vdots & \Ddots & \vdots\\
		\tikzmark{In1}0 & 0 & 0 & \cdots & 1\tikzmark{Inn}
	\end{bNiceMatrix}
	\label{eq:}
\end{equation}
\begin{tikzpicture}[overlay, remember picture]
	  \draw [xred, thick, decorate, decoration={brace, amplitude=3pt, raise=7pt}] (pic cs:I1n) -- (pic cs:Inn) node[midway, right, xshift=10pt]{$n$ rows};
	  \draw [xblue, thick, decorate, decoration={brace, amplitude=3pt, raise=10pt}] (pic cs:I11) -- (pic cs:I1n) node[midway, above, yshift=13pt]{$n$ columns};
\end{tikzpicture}

Sometimes for clarity large areas of zero-value elements in a matrix are depicted together. In that form, the identity matrix is written as
\[
	I_{n} =
	\begin{bNiceMatrix}
	1   &       & \Block{2-3}<\huge>{0} \\
		&   1   &        &      &       \\
		&       &   1    &      &       \\
	\Block{2-3}<\huge>{0}
		&       &       & \Ddots    &   \\
		&       &       &      &   1   \\
	\end{bNiceMatrix}.
\]
In such a depiction, the off-diagonal elements are each written using a single zero. This kind of notation will come in handy in later sections. Yet another way of defining the identity matrix is by using the \emph{Kronecker delta}, which takes two integers $i,j$ and returns $1$ if they are equal, otherwise it returns $0$:
\begin{equation}
	\delta_{ij} =
	\begin{cases}
		1 & i=j,\\
		0 & i\neq j.
	\end{cases}
	\label{eq:kronecker_delta}
\end{equation}
Using the Kronecker delta, each element $a_{ij}$ of the identity matrix $I_{n}$ simply equals $\delta_{ij}$.

An identity matrix of dimension $n$ represents the identity transformation in $\Rs{n}$: each standard basis vector $\eb{i}$ is left unchanged by the transformation.

\begin{example}{Identity matrices}{}
	The following are the identity matrices of $\Rs{2},\Rs{3},\dots,\Rs{6}$, where in each matrix the main diagonal is highlighted:

	\centering
	\setlength\tabcolsep{3pt}
	\begin{tabular}{ccccc}
		\IdentityHl{2}{I2}{xred!30} & \IdentityHl{3}{I3}{xblue!30} & \IdentityHl{4}{I4}{xgreen!30} & \IdentityHl{5}{I5}{xpurple!30} & \IdentityHl{6}{I6}{xorange!30} \\
		$I_{2}$ & $I_{3}$ & $I_{4}$ & $I_{5}$ & $I_{6}$
	\end{tabular}
\end{example}
In the next section we will see the importance of the identity matrices.

Another important family of matrices are the \emph{orthogonal matrices} (also \emph{orthonormal matrices}): we say that a matrix $Q$ is an orthogonal matrix if all of its columns, when viewed as column vectors, form an orthonormal set. For example, the identity matrices are all orthogonal matrices. Another orthogonal matrix is the matrix
\begin{equation}
	B = \frac{1}{\sqrt{2}}\begin{bmatrix}1&1\\1&-1\end{bmatrix},
	\label{eq:}
\end{equation}
since both $\frac{1}{\sqrt{2}}\colvec{1;1}$ and $\frac{1}{\sqrt{2}}\colvec{1;-1}$ are unit vectors, and they are orthogonal to each other (as seen in REF).

A \emph{symmetric matrix} is a square matrix for which
\begin{equation}
	A^{\top} = A.
	\label{eq:symmetric_matrix}
\end{equation}
"Graphically", the symmetry of such matrices can be seen in respect to their main diagonal: if we imagine placing a mirror on the main diagonal, each element $\Ma{i}{j}$ would be "reflected" across the mirror, and thus be equal to $\Ma{j}{i}$ (see example below).


\begin{example}{Symmetric matrix}{}
	The following matrix $S$ is a symmetric $4\times4$ matrix, in which the elements $a_{ij},a_{ji}$ are higlighted with the same color:

	\centering
	\begin{tikzpicture}[node distance=1.6cm]
		\node (Seq) {$S=$};
		\matrix (S) [matrix of nodes, right of=Seq, left delimiter={[}, right delimiter={]}]{
			1 & 3 & 5 & 7\\
			3 & 0 & 1 & 3\\
			5 & 1 & 4 & 2\\
			7 & 3 & 2 & 6\\
		};
		\tikzset{every node/.style={inner sep=0}}
		\scoped[on background layer]{
			\foreach \k in {1,...,4}
				\node[fill=white, fit=(S-\k-\k)(S-\k-\k)] {};
			\node[fill=xred!20, fit=(S-1-2)(S-1-2)] {};
			\node[fill=xred!20, fit=(S-2-1)(S-2-1)] {};
			\node[fill=xblue!20, fit=(S-1-3)(S-1-3)] {};
			\node[fill=xblue!20, fit=(S-3-1)(S-3-1)] {};
			\node[fill=xgreen!20, fit=(S-1-4)(S-1-4)] {};
			\node[fill=xgreen!20, fit=(S-4-1)(S-4-1)] {};
			\node[fill=xpurple!20, fit=(S-2-3)(S-2-3)] {};
			\node[fill=xpurple!20, fit=(S-3-2)(S-3-2)] {};
			\node[fill=xorange!20, fit=(S-2-4)(S-2-4)] {};
			\node[fill=xorange!20, fit=(S-4-2)(S-4-2)] {};
			\node[fill=xpink!20, fit=(S-3-4)(S-3-4)] {};
			\node[fill=xpink!20, fit=(S-4-3)(S-4-3)] {};
		}
	\end{tikzpicture}
\end{example}
\begin{note}{Transpose of a symmetric matrix}{}
	A symmetric matrix is its own transpose, i.e. if $A$ is a symmetric matrix then $A^{\top}=A$.
\end{note}

A rather non-interesting family of matrices are the \emph{zero matrices}: these are matrices which have only zero-elements, i.e.
\begin{equation}
	\bm{0}_{n} =
	\begin{bNiceMatrix}
		\tikzmark{z1}0 & 0 & \cdots & 0\tikzmark{z2}\\
		0 & 0 & \cdots & 0\\
		\vdots & \vdots & \Ddots & \vdots\\
		0 & 0 & \cdots & 0\tikzmark{z3}
	\end{bNiceMatrix}.
	\label{eq:}
\end{equation}
\begin{tikzpicture}[overlay, remember picture]
	  \draw [xred, thick, decorate, decoration={brace, amplitude=3pt, raise=7pt}] (pic cs:z2) -- (pic cs:z3) node[midway, right, xshift=10pt]{$m$ rows};
	  \draw [xblue, thick, decorate, decoration={brace, amplitude=3pt, raise=10pt}] (pic cs:z1) -- (pic cs:z2) node[midway, above, yshift=13pt]{$n$ columns};
\end{tikzpicture}
The zero matrices are called that way since for a given matrix $A$,
\begin{align}
	A + \bm{0} &=
	\begin{bNiceMatrix}
		\Ma{1}{1} & \Ma{1}{2} & \cdots & \Ma{1}{n}\\
		\Ma{2}{1} & \Ma{2}{2} & \cdots & \Ma{2}{n}\\
		\vdots & \vdots & \Ddots & \vdots\\
		\Ma{m}{1} & \Ma{m}{2} & \cdots & \Ma{m}{n}
	\end{bNiceMatrix}
	+
	\begin{bNiceMatrix}
		0 & 0 & \cdots & 0\\
		0 & 0 & \cdots & 0\\
		\vdots & \vdots & \Ddots & \vdots\\
		0 & 0 & \cdots & 0
	\end{bNiceMatrix}\nonumber\\
			   &=
	\begin{bNiceMatrix}
		\Ma{1}{1}+0 & \Ma{1}{2}+0 & \cdots & \Ma{1}{n}+0\\
		\Ma{2}{1}+0 & \Ma{2}{2}+0 & \cdots & \Ma{2}{n}+0\\
		\vdots & \vdots & \Ddots & \vdots\\
		\Ma{m}{1}+0 & \Ma{m}{2}+0 & \cdots & \Ma{m}{n}+0
	\end{bNiceMatrix}\nonumber\\
			   &=
	\begin{bNiceMatrix}
		\Ma{1}{1} & \Ma{1}{2} & \cdots & \Ma{1}{n}\\
		\Ma{2}{1} & \Ma{2}{2} & \cdots & \Ma{2}{n}\\
		\vdots & \vdots & \Ddots & \vdots\\
		\Ma{m}{1} & \Ma{m}{2} & \cdots & \Ma{m}{n}
	\end{bNiceMatrix}
	= A.
\end{align}
I.e. much like the number zero and the zero vector, the zero matrix is neutral in respect to addition.

\subsection{The determinant}
As mentioned in \autoref{sec:LS_developing_intuition}, linear transformation scale all volumes by the same amount\footnote{remember that 2-dimensional volumes are areas.}. This scaling factor is encapsulated in the matrix representing the transformation by a number called the \emph{determinant} of the matrix. The determinant of a matrix $A$ is written as $|A|$ and sometimes $\det(A)$.

\begin{example}{The determinant as a scaling factor}{}
	In the following transformation, represented by the matrix $A=\begin{bmatrix}\frac{1}{2}&0\\0&1\end{bmatrix}$, areas are scaled by a factor of $\frac{1}{2}$ and therefore $|A|=\frac{1}{2}$ (the number inside each shapes is its area):

	\center
	\begin{tikzpicture}
		\begin{axis}[
			vector plane,
			width=7cm, height=7cm,
			xmin=-5, xmax=5,
			ymin=-5, ymax=5,
			minor tick num=1,
			ticklabel style={font=\tiny},
		]
			\draw[thick, xred, fill=xred!20] (-4,-4) rectangle (-3,-3) node[shnode] {$1$};
			\draw[thick, xgreen, fill=xgreen!20] (-4,4) rectangle (-2,1) node[shnode] {$6$};
			\draw[thick, xpurple, fill=xpurple!20] (4,2) arc (0:360:1.2616) node[black, xshift=-7mm] {$5$};
		\end{axis}
		\pgftransformcm{1}{0}{0}{1}{\pgfpoint{7cm}{0}}
		\begin{axis}[
			vector plane,
			width=7cm, height=7cm,
			xmin=-10, xmax=10,
			ymin=-5, ymax=5,
			minor x tick num=2,
			minor y tick num=1,
			xtick={-8,-4,...,8},
			xticklabels={-4,-2,2,4},
			ticklabel style={font=\tiny},
		]
		\draw[thick, xred, fill=xred!20] (-4,-4) rectangle (-3,-3) node[shnode] {$\frac{1}{2}$};
		\draw[thick, xgreen, fill=xgreen!20] (-4,4) rectangle (-2,1) node[shnode] {$3$};
		\draw[thick, xpurple, fill=xpurple!20] (4,2) arc (0:360:0.8921) node[black, xshift=-2.5mm] {$\frac{5}{2}$};
		\end{axis}
		\draw[vector] (-1.3cm,3.5cm) -- ++(1cm,0) node[midway, above] {$A$} node[midway, below] {$|A|=\frac{1}{2}$};
	\end{tikzpicture}
\end{example}

Since there is not much sense in discussing volume changes between different spaces (e.g. $\Rs{5}\to\Rs{7}$), only square matrices, which as you recall represent linear transformations from a space onto itself, have determinants.

Zero determinant...\\
Negative determinant...

To calculate the determinant of a matrix, we start with the simplest case: $2\times2$ matrices. Since all areas are equaly scaled by a linear transformation, we look at the unit sqaure defined by $\hat{x}$ and $\hat{y}$ (see \autoref{fig:det_2x2}). After the application of the transformation represented by the generic matrix $A=\begin{bmatrix}a&c\\b&d\end{bmatrix}$ (where $a,b,c,d\in\mathbb{R}$), these basis vectors are transformed into the vectors 
\begin{equation}
	A\hat{x}=\colvec{a;b} \mkern9mu \text{and} \mkern9mu A\hat{y}=\colvec{c;d},
	\label{eq:}
\end{equation}
respectively.

\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			vector plane,
			width=6cm, height=6cm,
			xmin=-1, xmax=3,
			ymin=-1, ymax=3,
			xticklabels={,},
			yticklabels={,},
		]
			\fill[xpurple, opacity=0.2] (0,0) rectangle (1,1);
			\node[xpurple, anchor=center] at (0.5,0.5) {$S=1$};
			\draw[vector, xred] (0,0) -- (1,0) node[midway, below] {$\hat{x}$};
			\draw[vector, xblue] (0,0) -- (0,1) node[midway, left] {$\hat{y}$};
			\draw[vector, xred!50, dashed] (0,1) -- (1,1);
			\draw[vector, xblue!50, dashed] (1,0) -- (1,1);
		\end{axis}
		
		\pgftransformcm{1}{0}{0}{1}{\pgfpoint{7cm}{0}}
		\begin{axis}[
			vector plane,
			width=6cm, height=6cm,
			xmin=-1, xmax=3,
			ymin=-1, ymax=3,
			xticklabels={,},
			yticklabels={,},
		]
			\coordinate (Ax) at (0.5,1.5);
			\coordinate (Ay) at (1.5,0.5);
			\coordinate (Axy) at (2,2);
			\fill[xpurple, opacity=0.2] (0,0) -- (Ax) -- (Axy) -- (Ay) -- cycle;
			\node[xpurple, anchor=center] at (1,1) {$S=|A|$};
			\draw[vector, xred] (0,0) -- (Ax) node[pos=1.1, xshift=-6pt] {$A\hat{x}$};
			\draw[vector, xblue] (0,0) -- (Ay) node[pos=1.1, xshift=5pt, yshift=-3pt] {$A\hat{y}$};
			\draw[vector, xred!50, dashed] (Ay) -- (Axy);
			\draw[vector, xblue!50, dashed] (Ax) -- (Axy);
		\end{axis}
	\end{tikzpicture}
	\caption{Unit area defined by the vectors $\hat{x}$ and $\hat{y}$ before application of a linear transformation represented by the matrix $A$ (left) and the parallelogram defined by the vectors $A\hat{x}$ and $A\hat{y}$ after application of the transformation (right).}
	\label{fig:det_2x2}
\end{figure}

The unit square defined by $\hat{x}$ and $\hat{y}$ is therefore transformed into the parallelogram defined by $A\hat{x}$ and $A\hat{y}$. \autoref{eq:cross_product_2d_algebraic} tells us that the area of the parallelogram is $S=ad-bc$. Therefore, the determinant - which equals the change in area after application of $A$, is
\begin{equation}
	|A| = ad-bc
	\label{eq:determinant_2x2}
\end{equation}
as well.

\begin{example}{Determinants of $\bm{2\times2}$ matrices}{}
	Some $2\times2$ matrices and their determinants:

	\begin{align*}
		\begin{bmatrix} 1&-2\\0&3 \end{bmatrix} &\longrightarrow 1\cdot3-(-2)\cdot0 = 3.\\
		\begin{bmatrix} 1&5\\1&3 \end{bmatrix} &\longrightarrow 1\cdot3-1\cdot5 = -2.\\
		\begin{bmatrix} 1&2\\1&2 \end{bmatrix} &\longrightarrow 1\cdot2-1\cdot2 = 0.\\
		\begin{bmatrix} 1&2\\2&4 \end{bmatrix} &\longrightarrow 1\cdot4-2\cdot2 = 0.\\
		\begin{bmatrix} 0&7\\0&-3 \end{bmatrix} &\longrightarrow 0\cdot(-3)-0\cdot7 = 0.\\
	\end{align*}
\end{example}

Calculating the determinant of a $3\times3$ matrix is based on the calculation of the determinant of a $2\times2$ matrix. First, we should define an idea called a \emph{minor} of a matrix. The $ij$-minor of a $3\times3$ matrix $A$ is the determinant of the $2\times2$ matrix resulting by the removal of the $i$-th row and $j$-th column of $A$, e.g. let
\newcommand{\Aminor}[1]{
	\begin{bNiceMatrix}[name=#1]
		2 & -5 & 4\\
		-3 & 0 & 2\\
		3 & 3 & 2\\
	\end{bNiceMatrix}
}
\[
	A = \Aminor{A00},
\]
then \autoref{tab:minors_of_A} shows all the minors of $A$.

\begin{table}
	\centering
	\caption{All the minors of the matrix $A$.}
	\label{tab:minors_of_A}
	\begin{tabular}{lcccr}
		\toprule
		$i$ & $j$ & $3\times3$-matrix & $2\times2$ determinant & value\\
		\midrule
		$1$ & $1$ & $\Aminor{A11}$ & $\begin{vmatrix}0&2\\3&2\end{vmatrix}$   & $-6 $\\[10mm]
		$1$ & $2$ & $\Aminor{A12}$ & $\begin{vmatrix}-3&2\\3&2\end{vmatrix}$  & $-12$\\[10mm]
		$1$ & $3$ & $\Aminor{A13}$ & $\begin{vmatrix}-3&0\\3&3\end{vmatrix}$  & $-12$\\[10mm]
		$2$ & $1$ & $\Aminor{A21}$ & $\begin{vmatrix}-5&4\\3&2\end{vmatrix}$  & $-22$\\[10mm]
		$2$ & $2$ & $\Aminor{A22}$ & $\begin{vmatrix}2&4\\3&2\end{vmatrix}$   & $-8 $\\[10mm]
		$2$ & $3$ & $\Aminor{A23}$ & $\begin{vmatrix}2&-5\\3&3\end{vmatrix}$  & $ 21$\\[10mm]
		$3$ & $1$ & $\Aminor{A31}$ & $\begin{vmatrix}-5&4\\0&2\end{vmatrix}$  & $-10$\\[10mm]
		$3$ & $2$ & $\Aminor{A32}$ & $\begin{vmatrix}2&4\\-3&2\end{vmatrix}$  & $ 16$\\[10mm]
		$3$ & $3$ & $\Aminor{A33}$ & $\begin{vmatrix}2&-5\\-3&0\end{vmatrix}$ & $-15$\\
		\bottomrule
	\end{tabular}
	\begin{tikzpicture}[overlay, remember picture]
		\MatMinor{A11}{3}{1}{1}
		\MatMinor{A12}{3}{1}{2}
		\MatMinor{A13}{3}{1}{3}
		\MatMinor{A21}{3}{2}{1}
		\MatMinor{A22}{3}{2}{2}
		\MatMinor{A23}{3}{2}{3}
		\MatMinor{A31}{3}{3}{1}
		\MatMinor{A32}{3}{3}{2}
		\MatMinor{A33}{3}{3}{3}
	\end{tikzpicture}
\end{table}

\subsection{Matrix-vector products}
\subsection{Matrix-matrix products}
\subsection{Inverse matrices}
\subsection{Kernel and null space}
