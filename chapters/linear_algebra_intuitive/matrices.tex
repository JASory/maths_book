\section{Matrices}
In the previous section we described linear transformations in a rather abstract way: what they are, how they behave qualitatively and how they look like in 2- and 3-dimensions. In this section we introduce a numerical method of representing linear transformations: matrices.

\subsection{Linear transformation of basis vectors}
Recall that any vector $\vec{v}\in\Rs{n}$ can be written as a linear combination of basis vectors $\vec{b}_{1}, \vec{b}_{2}, \dots, \vec{b}_{n}$:
\begin{equation}
	\vec{v} = \sum\limits_{i=1}^{n}\alpha_{i}\vec{b}_{i} = \alpha_{1}\vec{b}_{1} + \alpha_{2}\vec{b}_{2} + \cdots + \alpha_{n}\vec{b}_{n}.
\end{equation}

Applying a linear transformation $T$ on $\vec{v}$ yields, using the properties of linear transformations,
\begin{align}
	T\left(\vec{v}\right) &= T\left(\alpha_{1}\vec{b}_{1} + \alpha_{2}\vec{b}_{2} + \cdots + \alpha_{n}\vec{b}_{n}\right)\nonumber\\
	\tikz[baseline=-0.5ex]{\draw[-stealth, xred] (0,0) -- (1,0) node[pos=-0.1, anchor=east] {additivity}}
						  &= T\left(\alpha_{1}\vec{b}_{1}\right) + T\left(\alpha_{2}\vec{b}_{2}\right) + \cdots + T\left(\alpha_{n}\vec{b}_{n}\right)\nonumber\\
    \tikz[baseline=-0.5ex]{\draw[-stealth, xblue] (0,0) -- (1,0) node[pos=-0.1, anchor=east] {scalability}}
						  &= \alpha_{1}T\left(\vec{b}_{1}\right) + \alpha_{2}T\left(\vec{b}_{2}\right) + \cdots + \alpha_{n}T\left(\vec{b}_{n}\right).
	\label{eq:transfom_by_basis}
\end{align}

This result is pretty neat: it means that by knowing how a linear transformation $T$ changes the basis vectors, we know exactly how any vector is transformed by $T$. This true for any basis, and thus specifically to the standard basis, where the coefficients $\alpha_{1},\alpha_{2},\dots,\alpha_{n}$ are actually the components of the vector, i.e. $v_{1},v_{2},\dots,v_{n}$. Thus in the standard basis:
\begin{equation}
	T\left(\vec{v}\right) = v_{1}T\left(\eb{1}\right) + v_{2}T\left(\eb{2}\right) + \cdots + v_{n}T\left(\eb{n}\right).
\end{equation}

\begin{example}{Vector transformation via a basis}{}
	Applying the transformation $T:\Rs{3}\to\Rs{3}$, defined as
	\[
		T\left(\colvec{x;y;z}\right)=\colvec{x+y-2z;2x+z;-x-y-z}
	\]
	on the vector $\vec{v}=\colvec{2;-1;3}$ yields the following vector:
	\[
		T\left(\vec{v}\right) = T\left(\colvec{2;-1;3}\right) = \colvec{2+(-1)-2\cdot3;2\cdot2+3;-2-(-1)-3} = \colvec{2-1-6;4+3;-2+1-3} = \colvec{-5;7;-4}.
	\]

	Now, let us apply $T$ first to the three standard basis vectors $\hat{x},\hat{y},\hat{z}$:
	\begin{align*}
		T\left( \hat{x} \right) &= T\left(\colvec{1;0;0}\right) = \colvec{1+0-2\cdot0;2\cdot1+0;-1-0-0} = \colvec{1;2;-1},\\
		T\left( \hat{y} \right) &= T\left(\colvec{0;1;0}\right) = \colvec{0+1-2\cdot0;2\cdot0+0;-0-1-0} = \colvec{1;0;-1},\\
		T\left( \hat{z} \right) &= T\left(\colvec{0;0;1}\right) = \colvec{0+0-2\cdot1;2\cdot0+1;-0-0-1} = \colvec{-2;1;-1}.
	\end{align*}

	Taking these results and applying \autoref{eq:transfom_by_basis} yields
	\begin{align*}
		T\left( \vec{v} \right) &= 2T \left( \hat{x} \right) -T \left( \hat{y} \right) + 3T \left( \hat{z} \right)\\
								&= 2\colvec{1;2;-1} - \colvec{1;0;-1} + 3\colvec{-2;1;-1}\\
								&= \colvec{2;4;-2} - \colvec{1;0;-1} + \colvec{-6;3;-3}\\
								&= \colvec{2-1-6;4-0+3;-2-(-1)+(-3)}\\
								&= \colvec{-5;7;-4},
	\end{align*}
	which is indeed what we got when we applied $T$ directly to $\vec{v}$.
\end{example}

\subsection{From transformations to matrices}
The most general linear transformation $T:\Rs{2}\to\Rs{2}$ has the following form:
\begin{equation}
	T \left( \colvec{x;y} \right) = \colvec{ax+by;cx+dy},
	\label{eq:generic_R2_LT}
\end{equation}
where $a,b,c,d\in\mathbb{R}$. If we apply this transformation to $\hat{x}$ and $\hat{y}$ we get, respectively,
\begin{equation}
	T \left( \hat{x} \right) = \colvec{a;c},\quad T \left( \hat{y} \right) = \colvec{b;d}.
	\label{eq:}
\end{equation}
We can now collect these two vectors to form a new structure, which we call a \emph{matrix} (in this specific casr a $2\times2$ matrix):
\begin{equation}
	M = \begin{bmatrix} a&b\\c&d \end{bmatrix}.
	\label{eq:matrix}
\end{equation}

We then define the product of $M$ with a vector $\vec{v}=\colvec{x;y}$ to yield $T \left( \vec{v} \right)$, i.e.
\begin{equation}
	M\vec{v} = \begin{bmatrix} a&b\\c&d \end{bmatrix} \cdot\colvec{x;y} = \colvec{ax+by;cx+dy}.
	\label{eq:matrix_vector_product}
\end{equation}
This defintion can be re-written as following:
\begin{equation}
	M\vec{v} = \begin{bmatrix} a&b\\c&d \end{bmatrix} \cdot\colvec{x;y} = \colvec{M_{1}\cdot\vec{v};M_{2}\cdot\vec{v}},
	\label{eq:matrix_vector_product_as_dot_product}
\end{equation}
i.e. the $i$-th component of the resulting vector is the scalar product of the $i$-th \textbf{row} of the matrix with the vector $\vec{v}$.

\begin{example}{Matrix-vector product}{}
	Some matrix-vector products:

	\begin{align*}
		\begin{bmatrix}
			1 & -2 \\
			0 & 5
		\end{bmatrix}\colvec{-3;2} &= \colvec{1\cdot(-3) + (-2)\cdot2;0\cdot(-3)+5\cdot2} = \colvec{-7;10},\\[5mm]
		\begin{bmatrix}
			1 & 2 \\
			1 & 2
		\end{bmatrix}\colvec{5;-4} &= \colvec{1\cdot5+2\cdot(-4);1\cdot5+2\cdot(-4)} = \colvec{-3;-3},\\[5mm]
		\begin{bmatrix}
			1 & 0 \\
			0 & 2
		\end{bmatrix}\colvec{2;-2} &= \colvec{2\cdot2+0\cdot(-2);0\cdot2+2\cdot(-2)} = \colvec{4;-4}.
	\end{align*}
\end{example}

\begin{challange}{Proof of linearity}{}
	Prove that the transformation $T$ in \autoref{eq:generic_R2_LT} is indeed linear.
\end{challange}

The most general form of a linear transformation is $T:\Rs{n}\to\Rs{m}$, i.e. a transformation which takes $n$-dimensional vectors as input and returns $m$-dimensional vectors as output:
\begin{equation}
	T \left( \colvec{\tikzmark{N}x_{1};x_{2};\vdots;x_{n}} \right) = \colvec{
		\Ma{1}{1}x_{1}+\Ma{1}{2}x_{2}+\cdots+\Ma{1}{n}x_{n};
		\Ma{2}{1}x_{1}+\Ma{2}{2}x_{2}+\cdots+\Ma{2}{n}x_{n}\tikzmark{M};
		\vdots;
		\Ma{m}{1}x_{1}+\Ma{m}{2}x_{2}+\cdots+\Ma{m}{n}x_{n}
	},
	\label{eq:}
\end{equation}
\begin{tikzpicture}[overlay, remember picture]
	\node[xblue] (Ntxt) at ($(pic cs:N)+(-1.5cm,-2mm)$) {$\Rs{n}\ni$};
	\draw[-stealth, xblue] (Ntxt) to [out=45, in=90] ($(pic cs:N)+(1mm,2.5mm)$);
	\node[xred] (Mtxt) at ($(pic cs:M)+(2.5cm,5mm)$) {$\in\Rs{m}$};
	\draw[-stealth, xred] (Mtxt) to [out=180, in=0] ($(pic cs:M)+(2.5mm,0)$);
\end{tikzpicture}

where $\Ma{i}{j}\in\mathbb{R},\ \textcolor{xred}{i}=1,2,3,\dots,m$ and $\textcolor{xblue}{j}=1,2,3,\dots,n$.

\begin{challange}{Proof of linearity}{}
	Prove that the above transformation $T$ is indeed linear.
\end{challange}

Respectively, we define an $\textcolor{xred}{m}\times \textcolor{xblue}{n}$ matrix (\textcolor{xred}{$m$} rows by \textcolor{xblue}{$n$} columns) by collecting all the coefficients $\Ma{i}{j}$ into a single structure:
\begin{equation}
	M =
	\begin{bmatrix}
		\Ma{1}{1} & \Ma{1}{2} & \cdots & \Ma{1}{n}\\
		\Ma{2}{1} & \Ma{2}{2} & \cdots & \Ma{2}{n}\\
		\vdots & \vdots & \ddots & \vdots\\
		\Ma{m}{1} & \Ma{m}{2} & \cdots & \Ma{m}{n}
	\end{bmatrix}. 
	\label{eq:mxn_matrix}
\end{equation}
The product $M\vec{v}$ (where $\vec{v}\in\Rs{n}$) is then defined as
\begin{equation}
	M\vec{v} =
	\begin{bmatrix}
		\Ma{1}{1} & \Ma{1}{2} & \cdots & \Ma{1}{n}\\
		\Ma{2}{1} & \Ma{2}{2} & \cdots & \Ma{2}{n}\\
		\vdots & \vdots & \ddots & \vdots\\
		\Ma{m}{1} & \Ma{m}{2} & \cdots & \Ma{m}{n}
	\end{bmatrix}\colvec{x_{1};x_{2};\vdots;x_{n}} = \colvec{
	\Ma{1}{1}x_{1}+\Ma{1}{2}x_{2}+\cdots+\Ma{1}{n}x_{n};
	\Ma{2}{1}x_{1}+\Ma{2}{2}x_{2}+\cdots+\Ma{2}{n}x_{n};
	\vdots;
	\Ma{m}{1}x_{1}+\Ma{m}{2}x_{2}+\cdots+\Ma{m}{n}x_{n}
	}.
	\label{eq:}
\end{equation}
Again, note that the $i$-th component of the resulting vector is the scalar product $M_{i}\cdot\vec{v}$.

\begin{note}{When is a matrix-vector product defined}{}
	In order for a matrix-vector product to be defined, the vector must be of the same dimension as the number of \textbf{columns} in the matrix - i.e. given an $a\times b$ matrix, a vector must be $b$-dimensional for the product to be defined.
\end{note}

\begin{example}{Some matrix-vector products}{}
	\blindtext[2]
\end{example}

The structure of an $m\times n$ matrix $M$ has a nice property: given that the transformation in represented in some basis $B=\left\{ \vec{b}_{1},\vec{b}_{2},\dots,\vec{b}_{n} \right\}$, the $i$-th column of the matrix always shows how $\vec{b}_{i}$ is transformed by the product $M\vec{b}_{n}$. This is easy to see in the case of the standard basis, which we anyway use througout this chapter:

\vspace{1cm}
\begin{equation*}
	\setlength{\arraycolsep}{2.7mm}
	M =
	\begin{bNiceMatrix}
		\tikzmark{A1}\Ma{1}{1} & \tikzmark{B1}\Ma{1}{2} & \cdots & \tikzmark{N1}\Ma{1}{n}\\
	    \Ma{2}{1} & \Ma{2}{2} & \cdots & \Ma{2}{n}\\
		\vdots & \vdots & \ddots & \vdots\\
		\Ma{m}{1}\tikzmark{A2} & \Ma{m}{2}\tikzmark{B2} & \cdots & \Ma{m}{n}\tikzmark{N2}
	\end{bNiceMatrix}.
\end{equation*}
\tikzset{
	highlight/.style={thick, draw=#1, rounded corners, draw opacity=1, fill=#1, fill opacity=0.2},
	hltxt/.style={highlight=#1, draw opacity=1, text=black, text opacity=1, above, yshift=1.5cm},
	hlarrow/.style={-stealth, thick, #1},
}
\tikz[overlay, remember picture, blend mode=multiply]{
	\draw[highlight={xgreen}]  ($(pic cs:A1)+(-2pt,7pt)$) rectangle node[hltxt={xgreen} ](Atxt){$T \left( \eb{1} \right)$}($(pic cs:A2)+(2pt,-5pt)$);
	\draw[highlight={xpurple}] ($(pic cs:B1)+(-2pt,7pt)$) rectangle node[hltxt={xpurple}](Btxt){$T \left( \eb{2} \right)$}($(pic cs:B2)+(2pt,-5pt)$);
	\draw[highlight={xorange}] ($(pic cs:N1)+(-2pt,7pt)$) rectangle node[hltxt={xorange}](Ntxt){$T \left( \eb{n} \right)$}($(pic cs:N2)+(2pt,-5pt)$);

	\draw[hlarrow={xgreen}]  (Atxt.south) -- ++(0,-5mm);
	\draw[hlarrow={xpurple}] (Btxt.south) -- ++(0,-5mm);
	\draw[hlarrow={xorange}] (Ntxt.south) -- ++(0,-5mm);
}

\begin{example}{Matrices}{}
	The product of the following matrix $M$ with each of the vectors $\eb{1},\eb{2},\eb{3}$ (i.e. $\hat{x},\hat{y}$ and $\hat{z}$, respectively) returns the respective column of the matrix:
	\begin{align*}
		M\eb{1}=
		\begin{bmatrix}
			 1 & 2 & 0\\
			-1 & 3 & 4\\
			 0 & 1 & 3\\
		 \end{bmatrix}\colvec{1;0;0} &= \colvec{1\cdot1+2\cdot0+0\cdot0;-1\cdot1+3\cdot0+4\cdot0;0\cdot1+1\cdot0+3\cdot0} = \colvec{1;-1;0},\\[3mm]
		M\eb{2}=
		\begin{bmatrix}
			 1 & 2 & 0\\
			-1 & 3 & 4\\
			 0 & 1 & 3\\
		\end{bmatrix}\colvec{0;1;0} &= \colvec{1\cdot0+2\cdot1+0\cdot0;-1\cdot0+3\cdot1+4\cdot0;0\cdot0+1\cdot1+3\cdot0} = \colvec{2;3;1},\\[3mm]
		M\eb{3}=
		\begin{bmatrix}
			 1 & 2 & 0\\
			-1 & 3 & 4\\
			 0 & 1 & 3\\
		\end{bmatrix}\colvec{0;0;1} &= \colvec{1\cdot0+2\cdot0+0\cdot1;-1\cdot0+3\cdot0+4\cdot1;0\cdot0+1\cdot0+3\cdot1} = \colvec{0;4;3}.
	\end{align*}
\end{example}

We can now represent all of the basic linear transformations in $\Rs{2}$ mentioned in the previous section (\autoref{fig:basicLinearTrans}) as $2\times2$ matrices. We do this by observing how the basis vectors $\hat{x}$ and $\hat{y}$ change after the application of each transformation.

\begin{descitemize}
	\item[Identity] both basis vectors remain the same: $\colvec{1;0}\to\colvec{1;0},\ \colvec{0;1}\to\colvec{0;1}$. Therefore the matrix $I$ representing the identity transformation is
		\begin{equation}
			I = \begin{bmatrix} 1&0 \\ 0&1 \end{bmatrix}.
		\end{equation}

	\item[Scaling in $x$ by $\alpha$] the basis vector $\hat{x}$ is streched by $\alpha$: $\colvec{1;0}\to\colvec{\alpha;0}$. The basis vector $\hat{y}=\colvec{0;1}$ stays the same. Therefore the matrix $S_{x}$ representing the transformation is
		\begin{equation}
			S_{x} = \begin{bmatrix} \alpha&0 \\ 0&1 \end{bmatrix}.
			\label{eq:}
		\end{equation}
	
	\item[Scaling in $y$ by $\beta$] much like with $S_{x}$, now the basis vector $\hat{y}$ is the one getting streched, by $\beta$: $\colvec{0;1}\to\colvec{0;\beta}$. The basis vector $\hat{x}=\colvec{1;0}$ stays the same. Therefore the matrix $S_{y}$ representing the transformation is
		\begin{equation}
			S_{y} = \begin{bmatrix} 1&0 \\ 0&\beta \end{bmatrix}.
			\label{eq:}
		\end{equation}

	\item[Rotating by $\theta$ counter-clockwise about the origin] \autoref{fig:rotationT} shows how do $\hat{x}$ and $\hat{y}$ transformed by the rotation. In the case of $\hat{x}$, the resulting vector is $R_{\theta} \left( \hat{x} \right)=\colvec{\cos(\theta),\sin(\theta)}$, since thiese are the respective sides of a right triangle of hypotenous $1$ and angle $\theta$. The components of $R_{\theta}\left(\hat{y}\right)$ can be calculated by rotating $\hat{x}$ by $\theta+\frac{\pi}{2}$ ($\theta+\ang{90}$): $\cos \left( \theta+\frac{\pi}{2} \right) = -\sin(\theta)$, and $\sin \left( \theta+\frac{\pi}{2} \right) = \cos \left( \theta \right)$. Therefore we get
		\begin{equation}
			\colvec{1;0} \to \colvec{\cos(\theta);\sin(\theta)},\ \colvec{0;1} \to \colvec{-\sin(\theta);\cos(\theta)}.
			\label{eq:}
		\end{equation}

		Altogether the rotation matrix $R_{\theta}$ is
		\begin{equation}
			R_{\theta} = \begin{bmatrix} \cos(\theta)&-\sin(\theta) \\ \sin(\theta)&\cos(\theta) \end{bmatrix}.
			\label{eq:}
		\end{equation}

		\begin{figure}
			\centering
			\begin{tikzpicture}
				\begin{axis}[
					vector plane,
					width=10cm, height=10cm,
					xmin=-1.3, xmax=1.3,
					ymin=-1.3, ymax=1.3,
					xtick={-1,0,1},
					ytick={-1,0,1},
					yticklabel pos=right,
					yticklabel style={anchor=west},
				]
				\pgfmathsetmacro{\t}{30};
				\draw[black!20] (1,0) arc (0:360:1);
				\tikzset{point/.style={circle, fill=#1, inner sep=0pt, minimum size=3pt}}

				% x
				\draw[vector, xred] (0,0) -- (1,0) node[midway, below] {$\hat{x}$};
				\draw[vector, xred, dashed] (0,0) -- ({cos(\t)},{sin(\t)}) node[midway, above, rotate=\t] {$R \left( \hat{x} \right)$};
				\fill[xpurple, opacity=0.15] (0,0) -- (1,0) arc (0:\t:1) -- cycle;
				\draw[vector, xpurple, dashed] (1,0) arc (0:\t:1) node[point={xred}] (rx) {};
				\node[text=xpurple] at ({1.1*cos(\t/2)},{1.1*sin(\t/2)}) {$\theta$};
				
				% y
				\draw[vector, xblue] (0,0) -- (0,1) node[midway, right] {$\hat{y}$};
				\draw[vector, xblue, dashed] (0,0) -- ({-sin(\t)},{cos(\t)}) node[midway, below, rotate={\t-90}] {$R \left( \hat{y} \right)$};
				\fill[xpurple, opacity=0.15] (0,0) -- (0,1) arc (90:{90+\t}:1) -- cycle;
				\draw[vector, xpurple, dashed] (0,1) arc (90:{90+\t}:1) node[point={xblue}] (ry) {};
				\node[text=xpurple] at ({-1.1*sin(\t/2)},{1.1*cos(\t/2)}) {$\theta$};
				\end{axis}
				\node[xred, anchor=west, yshift=5pt]  at (rx) {$\left(  \Ctrig,\Strig \right)$};
				\node[xblue, anchor=east, xshift=-4pt] at (ry) {$\left( -\Strig,\Ctrig \right)$};
			\end{tikzpicture}
			\caption{Rotation of $\textcolor{xred}{\hat{x}}$ and $\textcolor{xblue}{\hat{y}}$ by an angle $\textcolor{xpurple}{\theta}$ counter-clockwise about the origin. The notations $\Ctrig,\Strig$ stand for $\cos(\textcolor{xpurple}{\theta})$ and $\sin(\textcolor{xpurple}{\theta})$, respectively.}
			\label{fig:rotationT}
		\end{figure}
\end{descitemize}
